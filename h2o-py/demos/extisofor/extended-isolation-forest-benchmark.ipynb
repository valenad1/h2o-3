{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Isolation Forest Benchmark\n",
    "\n",
    "H2O cloud is inicialize before every run and shutdown after every run. Algorithm is firstly tested on Training performance and after on Evaluation performance.\n",
    "\n",
    "* N = number of rows\n",
    "* P = number of collumns\n",
    "* sample_size = how many rows will be used to built a tree\n",
    "* max_depth = only for IF, how big is the depth of the tree, in EIF is always set on math.ceil(math.log(sample_size, 2)) and max_depth is always depends on sample_size in benchmark\n",
    "\n",
    "Computer parameters:\n",
    " * Lenovo ThinkPad P53,\n",
    " * MS Windows 10 Pro x64,\n",
    " * Intel Core i7-9850H CPU @ 2.60GHz,\n",
    " * 6 cores and 12 threads,\n",
    " * 96.0 GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:/skola/dip/h2o-3/h2o-py/build/main\") # path to h2o build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import time\n",
    "import math\n",
    "import h2o\n",
    "from h2o.estimators import H2OIsolationForestEstimator\n",
    "from h2o.estimators import H2OExtendedIsolationForestEstimator\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook parameters\n",
    "\n",
    "seed = 1234\n",
    "ntrees = 100\n",
    "attempt_per_thread = 10 # number of runs of the algorithm in the thread\n",
    "threds = [12, 10, 8, 6, 4, 2, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(nthreads, data):\n",
    "    h2o.init(nthreads=nthreads)\n",
    "    hf = h2o.H2OFrame(data)\n",
    "    start = time.time()\n",
    "    EIF_h2o = H2OExtendedIsolationForestEstimator(model_id = \"extended_isolation_forest.hex\",\n",
    "                                         ntrees = ntrees, seed = seed, sample_size = sample_size, extension_level = P - 1)\n",
    "    EIF_h2o.train(training_frame = hf)\n",
    "    end = time.time()\n",
    "    eif_time = end - start\n",
    "    print(f\"EIF Time: {eif_time}s\")\n",
    "    start = time.time()\n",
    "    IF_h2o = H2OIsolationForestEstimator(model_id = \"isolation_forest.hex\",\n",
    "                                     ntrees = ntrees, seed = seed, sample_size = sample_size, max_depth = max_depth)\n",
    "    IF_h2o.train(training_frame = hf)\n",
    "    end = time.time()\n",
    "    if_time = end - start\n",
    "    print(f\"IF Time: {if_time}s\")\n",
    "    h2o.cluster().shutdown()\n",
    "    return eif_time, if_time\n",
    "\n",
    "\n",
    "def run_benchmark(data):\n",
    "    all_times = []\n",
    "    all_times_num_eif = []\n",
    "    all_times_num_if = []\n",
    "    for nthreads in threds:\n",
    "        times_eif = []\n",
    "        times_if = []\n",
    "        for i in range(attempt_per_thread):\n",
    "            eif_time, if_time = train_models(nthreads, data)\n",
    "            times_eif.append(eif_time)\n",
    "            times_if.append(if_time)\n",
    "        print(f\"EIF {np.mean(times_eif)}s\")\n",
    "        print(f\"IF {np.mean(times_if)}s\")\n",
    "        all_times_num_eif.append(times_eif)\n",
    "        all_times_num_if.append(times_if)\n",
    "        all_times.append(f\"thread {nthreads} - EIF {np.mean(times_eif)}s and IF {np.mean(times_if)}s\")\n",
    "\n",
    "    eif_means = dict()\n",
    "    if_means = dict()\n",
    "    for i, nthreads in enumerate(threds):\n",
    "        print(f\"{nthreads} - EIF = {np.mean(all_times_num_eif[i])}, IF = {np.mean(all_times_num_if[i])}\")\n",
    "        eif_means[nthreads] = np.mean(all_times_num_eif[i])\n",
    "        if_means[nthreads] = np.mean(all_times_num_if[i])\n",
    "    \n",
    "    return eif_means, if_means\n",
    "        \n",
    "    \n",
    "def plot_result(eif_means, if_means):\n",
    "    data = {\"x\":[], \"y\": [], \"label\":[]}\n",
    "    for label, coord in eif_means.items():\n",
    "        data[\"x\"].append(label)\n",
    "        data[\"y\"].append(coord)\n",
    "\n",
    "    data_if = {\"x\":[], \"y\": [], \"label\":[]}\n",
    "    for label, coord in if_means.items():\n",
    "        data_if[\"x\"].append(label)\n",
    "        data_if[\"y\"].append(coord)    \n",
    "\n",
    "    fig=plt.figure(figsize=(8,10))\n",
    "    fig.add_subplot(111)\n",
    "    plt.plot(data['x'], data['y'], '-', label=\"EIF\", linewidth=3)\n",
    "    plt.plot(data_if['x'], data_if['y'], '-', label=\"IF\", linewidth=3)\n",
    "    plt.xlabel(\"Number of threads\")\n",
    "    plt.ylabel(\"Computing time (s)\")\n",
    "    plt.legend()\n",
    "    plt.tick_params(direction='out', length=6, width=2) \n",
    "    plt.title(f\"Extended Isolation Forest - training benchmark\\nModel: N = {N}; P = {P}; ntrees = {ntrees}; sample_size = {sample_size};  max_depth = {max_depth}\")\n",
    "    plt.savefig(f\"h2o-scale-perf_{sample_size}_{N}_{coord}.png\", bbox_inches='tight', pad_inches=.05)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training stage\n",
    "### Toy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small data and small dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data parameters\n",
    "\n",
    "N = 500\n",
    "P = 2\n",
    "sample_size = 256\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "blobs_params = dict(random_state=seed, n_samples=N, n_features=P)\n",
    "X = make_blobs(centers=[[0 for i in range(P)] for i in range(P)], cluster_std=1, **blobs_params)[0]\n",
    "\n",
    "eif_time, if_time = run_benchmark(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small data and high dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data parameters\n",
    "\n",
    "N = 5000\n",
    "P = 30\n",
    "sample_size = 256\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "blobs_params = dict(random_state=seed, n_samples=N, n_features=P)\n",
    "X = make_blobs(centers=[[0 for i in range(P)] for i in range(P)], cluster_std=1, **blobs_params)[0]\n",
    "\n",
    "eif_time, if_time = run_benchmark(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big data - small dimension, small sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data parameters\n",
    "\n",
    "N = 1_500_000\n",
    "P = 2\n",
    "sample_size = 256\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "blobs_params = dict(random_state=seed, n_samples=N, n_features=P)\n",
    "X = make_blobs(centers=[[0 for i in range(P)] for i in range(P)], cluster_std=1, **blobs_params)[0]\n",
    "\n",
    "eif_time, if_time = run_benchmark(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big data - high dimension, small sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data parameters\n",
    "\n",
    "N = 100_000\n",
    "P = 30\n",
    "sample_size = 256\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "blobs_params = dict(random_state=seed, n_samples=N, n_features=P)\n",
    "X = make_blobs(centers=[[0 for i in range(P)] for i in range(P)], cluster_std=1, **blobs_params)[0]\n",
    "\n",
    "eif_time, if_time = run_benchmark(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big data - small dimension, big sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data parameters\n",
    "\n",
    "N = 1_500_000\n",
    "P = 2\n",
    "sample_size = 15_000\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "blobs_params = dict(random_state=seed, n_samples=N, n_features=P)\n",
    "X = make_blobs(centers=[[0 for i in range(P)] for i in range(P)], cluster_std=1, **blobs_params)[0]\n",
    "\n",
    "eif_time, if_time = run_benchmark(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big data - high dimension, big sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data parameters\n",
    "\n",
    "N = 100_000\n",
    "P = 30\n",
    "sample_size = 10_000\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "blobs_params = dict(random_state=seed, n_samples=N, n_features=P)\n",
    "X = make_blobs(centers=[[0 for i in range(P)] for i in range(P)], cluster_std=1, **blobs_params)[0]\n",
    "\n",
    "eif_time, if_time = run_benchmark(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Credit Card Fraud Detection Data\n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data parameters\n",
    "\n",
    "df = pd.read_csv(\"creditcard.csv\", nrows=1)\n",
    "columns = df.columns.tolist()\n",
    "cols_to_use = columns[:len(columns)-1]\n",
    "df = pd.read_csv(\"creditcard.csv\", usecols=cols_to_use)\n",
    "\n",
    "\n",
    "N = df.shape[0]\n",
    "P = df.shape[1]\n",
    "sample_size = int(df.shape[0] * 0.01)\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "print(N, P, sample_size, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eif_time, if_time = run_benchmark(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data parameters\n",
    "\n",
    "df = pd.read_csv(\"creditcard.csv\", nrows=1)\n",
    "columns = df.columns.tolist()\n",
    "cols_to_use = columns[:len(columns)-1]\n",
    "df = pd.read_csv(\"creditcard.csv\", usecols=cols_to_use)\n",
    "\n",
    "\n",
    "N = df.shape[0]\n",
    "P = df.shape[1]\n",
    "sample_size = int(df.shape[0] * 0.05)\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "print(N, P, sample_size, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eif_time, if_time = run_benchmark(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(EIF_model, IF_model, hf_test):\n",
    "    start = time.time()\n",
    "    EIF_model.predict(hf_test)\n",
    "    end = time.time()\n",
    "    eif_time = end - start\n",
    "    print(f\"EIF Time: {eif_time}s\")\n",
    "    start = time.time()\n",
    "    IF_model.predict(hf_test)\n",
    "    end = time.time()\n",
    "    if_time = end - start\n",
    "    print(f\"IF Time: {if_time}s\")    \n",
    "    return eif_time, if_time\n",
    "\n",
    "\n",
    "def run_predict_benchmark(train_data, test_data):\n",
    "    all_times = []\n",
    "    all_times_num_eif = []\n",
    "    all_times_num_if = []\n",
    "    for nthreads in threds:\n",
    "        times_eif = []\n",
    "        times_if = []\n",
    "        h2o.init(nthreads=nthreads)     \n",
    "        hf_train = h2o.H2OFrame(train_data)    \n",
    "        hf_test = h2o.H2OFrame(test_data)\n",
    "        EIF_model = H2OExtendedIsolationForestEstimator(model_id = \"extended_isolation_forest.hex\",\n",
    "                                             ntrees = ntrees, seed = seed, sample_size = sample_size, extension_level = P - 1)\n",
    "        EIF_model.train(training_frame = hf_train)\n",
    "        IF_model = H2OIsolationForestEstimator(model_id = \"isolation_forest.hex\",\n",
    "                                         ntrees = ntrees, seed = seed, sample_size = sample_size, max_depth = max_depth)\n",
    "        IF_model.train(training_frame = hf_train)\n",
    "        for i in range(attempt_per_thread):\n",
    "            eif_time, if_time = run_predict(EIF_model, IF_model, hf_test)\n",
    "            times_eif.append(eif_time)\n",
    "            times_if.append(if_time)\n",
    "        h2o.cluster().shutdown()\n",
    "        print(f\"EIF {np.mean(times_eif)}s\")\n",
    "        print(f\"IF {np.mean(times_if)}s\")\n",
    "        all_times_num_eif.append(times_eif)\n",
    "        all_times_num_if.append(times_if)\n",
    "        all_times.append(f\"thread {nthreads} - EIF {np.mean(times_eif)}s and IF {np.mean(times_if)}s\")\n",
    "        \n",
    "        eif_means = dict()\n",
    "        if_means = dict()\n",
    "        for i, nthreads in enumerate(threds):\n",
    "            print(f\"{nthreads} - EIF = {np.mean(all_times_num_eif[i])}, IF = {np.mean(all_times_num_if[i])}\")\n",
    "            eif_means[nthreads] = np.mean(all_times_num_eif[i])\n",
    "            if_means[nthreads] = np.mean(all_times_num_if[i])\n",
    "\n",
    "        return eif_means, if_means\n",
    "\n",
    "\n",
    "def plot_predict(EIF_means, IF_means):\n",
    "    data = {\"x\":[], \"y\": [], \"label\":[]}\n",
    "    for label, coord in EIF_means.items():\n",
    "        data[\"x\"].append(label)\n",
    "        data[\"y\"].append(coord)\n",
    "\n",
    "    data_if = {\"x\":[], \"y\": [], \"label\":[]}\n",
    "    for label, coord in IF_means.items():\n",
    "        data_if[\"x\"].append(label)\n",
    "        data_if[\"y\"].append(coord)    \n",
    "\n",
    "    fig=plt.figure(figsize=(8,10))\n",
    "    fig.add_subplot(111)\n",
    "    plt.plot(data['x'], data['y'], '-', label=\"EIF\", linewidth=3)\n",
    "    plt.plot(data_if['x'], data_if['y'], '-', label=\"IF\", linewidth=3)\n",
    "    # plt.grid(\"off\")\n",
    "    plt.xlabel(\"Number of threads\")\n",
    "    plt.ylabel(\"Computing time (s)\")\n",
    "    plt.legend()\n",
    "    plt.tick_params(direction='out', length=6, width=2) \n",
    "    plt.title(f\"Extended Isolation Forest - evaluation benchmark\\nModel: N = {N_train}; P = {P}; ntrees = {ntrees}; sample_size = {sample_size};  max_depth = {max_depth}\\nEvaluation Frame: N = {N}; P = {P}\")\n",
    "    plt.savefig(f\"h2o-eval-perf_{sample_size}_{N}_{coord}.png\", bbox_inches='tight', pad_inches=.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation stage parameters\n",
    "\n",
    "N = 100_000\n",
    "P = 30\n",
    "N_train = 500_000\n",
    "sample_size = 10_000\n",
    "max_depth = math.ceil(math.log(sample_size, 2))\n",
    "\n",
    "blobs_params = dict(random_state=seed, n_samples=N_train, n_features=P)\n",
    "X_train = make_blobs(centers=[[0 for i in range(P)] for i in range(P)], cluster_std=1, **blobs_params)[0]\n",
    "\n",
    "blobs_params = dict(random_state=seed, n_samples=N, n_features=P)\n",
    "X_test = make_blobs(centers=[[0 for i in range(P)] for i in range(P)], cluster_std=1, **blobs_params)[0]\n",
    "\n",
    "eif_time, if_time = run_predict_benchmark(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predict(eif_time, if_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
